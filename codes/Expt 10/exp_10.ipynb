{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fK--r6mZnjxr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design and implement a CNN model (with 4+ layers of convolutions) to classify multi category image datasets. Use the MNIST, Fashion MNIST, CIFAR-10 datasets. Set the No. of Epoch as 5 and 10 . Make the necessary changes whenever required. Record the accuracy corresponding to the number of epochs. Record the time required to run the program, using CPU as well as using GPU in Colab."
      ],
      "metadata": {
        "id": "cyBWDrEmnn0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist, cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Detect device\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name:\n",
        "    print(f\"ğŸ’» GPU is available: {device_name}\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPU not found. Using CPU...\")\n",
        "\n",
        "# Smaller CNN (4 conv layers)\n",
        "def build_small_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Data loader and preprocessor\n",
        "def prepare_dataset(name):\n",
        "    if name == \"mnist\":\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "        x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "        x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "    elif name == \"fashion_mnist\":\n",
        "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "        x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "        x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "    elif name == \"cifar10\":\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    else:\n",
        "        raise ValueError(\"Unknown dataset\")\n",
        "\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "    y_train = to_categorical(y_train, 10)\n",
        "    y_test = to_categorical(y_test, 10)\n",
        "\n",
        "    # Reduce data for faster CPU training\n",
        "    x_train = x_train[:10000]\n",
        "    y_train = y_train[:10000]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, x_train.shape[1:]\n",
        "\n",
        "# Training and evaluation\n",
        "def train_model(dataset_name, epochs_list=[5, 10]):\n",
        "    print(f\"\\nğŸ“¦ Dataset: {dataset_name}\")\n",
        "    x_train, y_train, x_test, y_test, input_shape = prepare_dataset(dataset_name)\n",
        "\n",
        "    results = []\n",
        "    for epochs in epochs_list:\n",
        "        model = build_small_cnn_model(input_shape, 10)\n",
        "        start = time.time()\n",
        "        history = model.fit(x_train, y_train, epochs=epochs, batch_size=64,\n",
        "                            validation_split=0.1, verbose=0)\n",
        "        end = time.time()\n",
        "\n",
        "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "        duration = end - start\n",
        "        print(f\"ğŸ§ª Epochs: {epochs} | Accuracy: {test_acc:.4f} | Time: {duration:.2f}s\")\n",
        "        results.append((epochs, test_acc, duration))\n",
        "    return results\n",
        "\n",
        "# Run for each dataset\n",
        "all_results = {}\n",
        "datasets = [\"mnist\", \"fashion_mnist\"]  # You can add \"cifar10\" if running on GPU\n",
        "for name in datasets:\n",
        "    all_results[name] = train_model(name)\n",
        "\n",
        "# Print final summary\n",
        "print(\"\\nâœ… Summary (CPU Optimized):\")\n",
        "print(\"Dataset\\t\\tEpochs\\tAccuracy\\tTime (s)\")\n",
        "for dataset, records in all_results.items():\n",
        "    for epochs, acc, dur in records:\n",
        "        print(f\"{dataset}\\t{epochs}\\t{acc:.4f}\\t\\t{dur:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOAK5QAFno0q",
        "outputId": "8dc93e9c-c104-4433-8193-3bd19a8bd1dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ GPU not found. Using CPU...\n",
            "\n",
            "ğŸ“¦ Dataset: mnist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª Epochs: 5 | Accuracy: 0.9766 | Time: 49.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª Epochs: 10 | Accuracy: 0.9801 | Time: 92.74s\n",
            "\n",
            "ğŸ“¦ Dataset: fashion_mnist\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª Epochs: 5 | Accuracy: 0.8619 | Time: 44.93s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª Epochs: 10 | Accuracy: 0.8785 | Time: 96.54s\n",
            "\n",
            "âœ… Summary (CPU Optimized):\n",
            "Dataset\t\tEpochs\tAccuracy\tTime (s)\n",
            "mnist\t5\t0.9766\t\t49.26\n",
            "mnist\t10\t0.9801\t\t92.74\n",
            "fashion_mnist\t5\t0.8619\t\t44.93\n",
            "fashion_mnist\t10\t0.8785\t\t96.54\n"
          ]
        }
      ]
    }
  ]
}